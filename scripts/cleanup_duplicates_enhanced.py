#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆå»é‡è„šæœ¬
æ›´æ™ºèƒ½åœ°è¯†åˆ«å’Œæ¸…ç†é‡å¤æ•°æ®
"""

import os
import sys
import pathlib
from dotenv import load_dotenv
from supabase import create_client
from datetime import datetime, timedelta
import re

# åŠ è½½ç¯å¢ƒå˜é‡
env_path = pathlib.Path(__file__).parent.parent / '.env'
load_dotenv(dotenv_path=env_path)

url = os.getenv('SUPABASE_URL')
key = os.getenv('SUPABASE_KEY')
supabase = create_client(url, key)

def normalize_title(title):
    """æ ‡å‡†åŒ–æ ‡é¢˜ï¼Œç”¨äºå»é‡æ¯”è¾ƒ"""
    if not title:
        return ""
    
    # å»é™¤æ‹¬å·åŠå…¶å†…å®¹
    normalized = re.sub(r'[\(ï¼ˆ].*?[\)ï¼‰]', '', title)
    # å»é™¤å¸¸è§å‰ç¼€
    normalized = re.sub(r'^å†…æ¨[|-]?', '', normalized)
    normalized = re.sub(r'^å†…æ¨ç¾¤[|-]?', '', normalized)
    # å»é™¤å¤šä½™ç©ºæ ¼
    normalized = re.sub(r'\s+', '', normalized)
    # å»é™¤å¸¸è§åˆ†éš”ç¬¦
    normalized = normalized.replace('-', '').replace('|', '').replace('ï¼š', '').replace(':', '')
    # å»é™¤å¼•å·
    normalized = normalized.replace('"', '').replace('"', '').replace('"', '').replace('"', '')
    return normalized.strip()

def extract_keywords(title):
    """æå–æ ‡é¢˜ä¸­çš„å…³é”®è¯ï¼ˆå…¬å¸åã€å²—ä½åç­‰ï¼‰"""
    # æå–æ‰€æœ‰ä¸­æ–‡å­—è¯
    keywords = set(re.findall(r'[\u4e00-\u9fa5]+', title))
    # è¿‡æ»¤æ‰å¤ªçŸ­çš„è¯ï¼ˆå°‘äº2ä¸ªå­—ï¼‰
    keywords = {k for k in keywords if len(k) >= 2}
    return keywords

def are_similar(title1, title2):
    """åˆ¤æ–­ä¸¤ä¸ªæ ‡é¢˜æ˜¯å¦ç›¸ä¼¼ï¼ˆé‡å¤ï¼‰"""
    normalized1 = normalize_title(title1)
    normalized2 = normalize_title(title2)
    
    # å®Œå…¨åŒ¹é…
    if normalized1 == normalized2:
        return True
    
    # åŒ…å«å…³ç³»
    if normalized1 in normalized2 or normalized2 in normalized1:
        return True
    
    # å…³é”®è¯é‡å åº¦
    keywords1 = extract_keywords(normalized1)
    keywords2 = extract_keywords(normalized2)
    
    if keywords1 and keywords2:
        overlap = len(keywords1 & keywords2) / max(len(keywords1), len(keywords2))
        if overlap >= 0.7:  # 70% é‡å åº¦
            return True
    
    return False

def cleanup_duplicates():
    """æ¸…ç†é‡å¤æ•°æ®"""
    print("ğŸ” å¼€å§‹æŸ¥æ‰¾é‡å¤æ•°æ®...\n")
    
    # è·å–æ‰€æœ‰æ´»è·ƒçš„è®°å½•
    result = supabase.table("events")\
        .select("id, title, type, source_group, created_at, key_info")\
        .eq("status", "active")\
        .order("created_at", desc=False)\
        .execute()
    
    if not result.data:
        print("âœ… æ²¡æœ‰æ•°æ®éœ€è¦æ£€æŸ¥")
        return
    
    print(f"ğŸ“Š å…±æ‰¾åˆ° {len(result.data)} æ¡è®°å½•\n")
    
    # æŒ‰ç±»å‹åˆ†ç»„
    by_type = {}
    for record in result.data:
        event_type = record.get('type')
        if event_type not in by_type:
            by_type[event_type] = []
        by_type[event_type].append(record)
    
    duplicates_to_delete = []
    
    # å¯¹æ¯ç§ç±»å‹è¿›è¡Œæ£€æŸ¥
    for event_type, records in by_type.items():
        print(f"ğŸ” æ£€æŸ¥ {event_type} ç±»å‹çš„æ•°æ®ï¼ˆå…± {len(records)} æ¡ï¼‰...")
        
        # ä¸¤ä¸¤æ¯”è¾ƒ
        for i, record1 in enumerate(records):
            if record1['id'] in duplicates_to_delete:
                continue
            
            for j, record2 in enumerate(records[i+1:], start=i+1):
                if record2['id'] in duplicates_to_delete:
                    continue
                
                if are_similar(record1['title'], record2['title']):
                    # ä¿ç•™åˆ›å»ºæ—¶é—´æ›´æ—©çš„ï¼ˆæˆ–æ›´å®Œæ•´çš„ï¼‰
                    # æ¯”è¾ƒ key_info çš„å®Œæ•´æ€§
                    info1 = record1.get('key_info', {})
                    info2 = record2.get('key_info', {})
                    
                    # è®¡ç®—ä¿¡æ¯å®Œæ•´åº¦
                    def completeness(info):
                        count = 0
                        for key in ['company', 'position', 'deadline', 'location', 'link']:
                            if info.get(key):
                                count += 1
                        return count
                    
                    comp1 = completeness(info1)
                    comp2 = completeness(info2)
                    
                    # ä¿ç•™ä¿¡æ¯æ›´å®Œæ•´çš„ï¼Œå¦‚æœä¸€æ ·åˆ™ä¿ç•™æ›´æ—©çš„
                    if comp2 > comp1:
                        to_delete = record1['id']
                        keep = record2
                    elif comp1 > comp2:
                        to_delete = record2['id']
                        keep = record1
                    else:
                        # ä¿¡æ¯å®Œæ•´åº¦ç›¸åŒï¼Œä¿ç•™æ›´æ—©çš„
                        if record1['created_at'] < record2['created_at']:
                            to_delete = record2['id']
                            keep = record1
                        else:
                            to_delete = record1['id']
                            keep = record2
                    
                    duplicates_to_delete.append(to_delete)
                    print(f"  âš ï¸  å‘ç°é‡å¤ï¼š")
                    print(f"     ä¿ç•™ï¼š{keep['title']} (ID: {keep['id']}, åˆ›å»ºæ—¶é—´: {keep['created_at']})")
                    print(f"     åˆ é™¤ï¼š{record1['id'] if to_delete == record1['id'] else record2['id']} - {record1['title'] if to_delete == record1['id'] else record2['title']}")
                    print()
    
    if not duplicates_to_delete:
        print("âœ… æ²¡æœ‰å‘ç°é‡å¤æ•°æ®")
        return
    
    print(f"\nğŸ“‹ å…±å‘ç° {len(duplicates_to_delete)} æ¡é‡å¤æ•°æ®éœ€è¦åˆ é™¤")
    print(f"   é‡å¤IDåˆ—è¡¨: {duplicates_to_delete}\n")
    
    # ç¡®è®¤åˆ é™¤
    confirm = input("ç¡®è®¤åˆ é™¤è¿™äº›é‡å¤æ•°æ®ï¼Ÿ(yes/no): ").strip().lower()
    if confirm not in ['yes', 'y']:
        print("âŒ å·²å–æ¶ˆ")
        return
    
    # æ‰§è¡Œåˆ é™¤
    deleted_count = 0
    for dup_id in duplicates_to_delete:
        try:
            result = supabase.table("events").delete().eq("id", dup_id).execute()
            deleted_count += 1
            print(f"âœ… å·²åˆ é™¤ ID {dup_id}")
        except Exception as e:
            print(f"âŒ åˆ é™¤ ID {dup_id} å¤±è´¥: {e}")
    
    print(f"\nğŸ‰ æ¸…ç†å®Œæˆï¼å…±åˆ é™¤ {deleted_count} æ¡é‡å¤æ•°æ®")

if __name__ == "__main__":
    cleanup_duplicates()





